
# ğŸ” SHL Assessment Recommender

An AI-powered system that simplifies the selection of SHL **Individual Test Solutions** by taking natural language queries or job descriptions and returning the most relevant assessments.

---

## ğŸŒ Live Demo & API (Replace with your real links)

| Component         | URL                                                    |
|------------------|---------------------------------------------------------|
| ğŸ§ª Streamlit Demo | https://your-streamlit-url.streamlit.app               |
| ğŸ”— API Endpoint   | https://your-render-api.onrender.com/recommend?query= |
| ğŸ’» GitHub Repo    | https://github.com/yourusername/shl-assessment-recommender |

---

## ğŸ¯ Features

- Accepts natural language job descriptions or queries.
- Returns **1â€“10 relevant SHL Individual Test Solutions**.
- Each result includes:
  - ğŸ”— Assessment name (linked to SHL catalog)
  - âœ… Remote Testing Support (Yes/No)
  - ğŸ”„ Adaptive/IRT Support (Yes/No)
  - ğŸ§ª Test Type (A, B, C, etc.)

---

## ğŸ›  Tech Stack

- **Python** â€“ Core language
- **Streamlit** â€“ Frontend
- **FastAPI** â€“ Backend API
- **sentence-transformers** â€“ For semantic embeddings
- **BeautifulSoup & requests** â€“ For scraping SHL's catalog
- **NumPy** â€“ For cosine similarity
- **Uvicorn** â€“ ASGI server for FastAPI

---

## ğŸš€ Quick Start Guide

### ğŸ§± 1. Clone the Repo

```bash
git clone https://github.com/yourusername/shl-assessment-recommender.git
cd shl-assessment-recommender

ğŸ“¦ 2. Install Dependencies

pip install -r requirements.txt



â¸»

ğŸ§ª Run the App Locally

ğŸ”¹ A. Scrape SHL Assessment Data

python app/scraper.py

ğŸ”¹ B. Generate Embeddings

python app/embedding_model.py

ğŸ”¹ C. Start the Streamlit Frontend

streamlit run streamlit_app.py

Open browser: http://localhost:8501

ğŸ”¹ D. Start the FastAPI Backend

uvicorn api.main:app --reload

Test in browser:
	â€¢	API Endpoint: http://localhost:8000/recommend?query=Looking for Python developer
	â€¢	Swagger Docs: http://localhost:8000/docs

â¸»

ğŸ§  Evaluation Metrics

Supports these ranking-based evaluation metrics:
	â€¢	Mean Recall@K
	â€¢	MAP@K (Mean Average Precision)

âœ… Results are returned in descending similarity order, making it compatible with SHLâ€™s eval framework.

â¸»

ğŸ§¾ Example Queries to Try
	â€¢	I am hiring for Java developers who can collaborate with business teams.
	â€¢	Looking for Python, SQL, and JavaScript developers within 60 minutes.
	â€¢	Here is a JD text, can you recommend assessments under 30 minutes?
	â€¢	I want to assess cognitive and personality traits for an analyst role.

â¸»

ğŸ“ Project Structure

shl-assessment-recommender/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ scraper.py
â”‚   â”œâ”€â”€ recommender.py
â”‚   â”œâ”€â”€ embedding_model.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ assessments.json
â”‚   â””â”€â”€ embeddings.npy
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ approach.pdf



â¸»

ğŸ™‹ Author

Built with ğŸ’¡ by Shubhang Pareek
For the SHL GenAI Challenge 2025